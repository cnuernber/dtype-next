<!DOCTYPE html PUBLIC ""
    "">
<html><head><meta charset="UTF-8" /><title>tech.v3.tensor documentation</title><link rel="stylesheet" type="text/css" href="css/default.css" /><link rel="stylesheet" type="text/css" href="highlight/solarized-light.css" /><script type="text/javascript" src="highlight/highlight.min.js"></script><script type="text/javascript" src="js/jquery.min.js"></script><script type="text/javascript" src="js/page_effects.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body><div id="header"><h2>Generated by <a href="https://github.com/weavejester/codox">Codox</a> with <a href="https://github.com/xsc/codox-theme-rdash">RDash UI</a> theme</h2><h1><a href="index.html"><span class="project-title"><span class="project-name">dtype-next</span> <span class="project-version">6.01</span></span></a></h1></div><div class="sidebar primary"><h3 class="no-link"><span class="inner">Project</span></h3><ul class="index-link"><li class="depth-1 "><a href="index.html"><div class="inner">Index</div></a></li></ul><h3 class="no-link"><span class="inner">Topics</span></h3><ul><li class="depth-1 "><a href="buffered-image.html"><div class="inner"><span>Buffered Image Support</span></div></a></li><li class="depth-1 "><a href="cheatsheet.html"><div class="inner"><span>Cheatsheet</span></div></a></li><li class="depth-1 "><a href="datatype-to-dtype-next.html"><div class="inner"><span>Why dtype-next?</span></div></a></li><li class="depth-1 "><a href="dimensions-bytecode-gen.html"><div class="inner"><span>Dimensions and Bytecode Generation</span></div></a></li><li class="depth-1 "><a href="overview.html"><div class="inner"><span>Overview</span></div></a></li></ul><h3 class="no-link"><span class="inner">Namespaces</span></h3><ul><li class="depth-1"><div class="no-link"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>tech</span></div></div></li><li class="depth-2"><div class="no-link"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>v3</span></div></div></li><li class="depth-3"><a href="tech.v3.datatype.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>datatype</span></div></a></li><li class="depth-4 branch"><a href="tech.v3.datatype.argops.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>argops</span></div></a></li><li class="depth-4 branch"><a href="tech.v3.datatype.bitmap.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>bitmap</span></div></a></li><li class="depth-4 branch"><a href="tech.v3.datatype.datetime.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>datetime</span></div></a></li><li class="depth-4 branch"><a href="tech.v3.datatype.errors.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>errors</span></div></a></li><li class="depth-4 branch"><a href="tech.v3.datatype.ffi.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>ffi</span></div></a></li><li class="depth-4 branch"><a href="tech.v3.datatype.functional.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>functional</span></div></a></li><li class="depth-4 branch"><a href="tech.v3.datatype.jna.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>jna</span></div></a></li><li class="depth-4 branch"><a href="tech.v3.datatype.list.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>list</span></div></a></li><li class="depth-4 branch"><a href="tech.v3.datatype.mmap.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>mmap</span></div></a></li><li class="depth-4 branch"><a href="tech.v3.datatype.mmap-writer.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>mmap-writer</span></div></a></li><li class="depth-4 branch"><a href="tech.v3.datatype.native-buffer.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>native-buffer</span></div></a></li><li class="depth-4 branch"><a href="tech.v3.datatype.nippy.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>nippy</span></div></a></li><li class="depth-4 branch"><a href="tech.v3.datatype.packing.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>packing</span></div></a></li><li class="depth-4 branch"><a href="tech.v3.datatype.reductions.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>reductions</span></div></a></li><li class="depth-4 branch"><a href="tech.v3.datatype.rolling.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>rolling</span></div></a></li><li class="depth-4"><a href="tech.v3.datatype.struct.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>struct</span></div></a></li><li class="depth-3"><div class="no-link"><div class="inner"><span class="tree" style="top: -517px;"><span class="top" style="height: 526px;"></span><span class="bottom"></span></span><span>libs</span></div></div></li><li class="depth-4 branch"><a href="tech.v3.libs.buffered-image.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>buffered-image</span></div></a></li><li class="depth-4"><a href="tech.v3.libs.neanderthal.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>neanderthal</span></div></a></li><li class="depth-3"><div class="no-link"><div class="inner"><span class="tree" style="top: -83px;"><span class="top" style="height: 92px;"></span><span class="bottom"></span></span><span>parallel</span></div></div></li><li class="depth-4"><a href="tech.v3.parallel.for.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>for</span></div></a></li><li class="depth-3 current"><a href="tech.v3.tensor.html"><div class="inner"><span class="tree" style="top: -52px;"><span class="top" style="height: 61px;"></span><span class="bottom"></span></span><span>tensor</span></div></a></li><li class="depth-4 branch"><a href="tech.v3.tensor.color-gradients.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>color-gradients</span></div></a></li><li class="depth-4"><a href="tech.v3.tensor.dimensions.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>dimensions</span></div></a></li></ul></div><div class="sidebar secondary"><h3><a href="#top"><span class="inner">Public Vars</span></a></h3><ul><li class="depth-1"><a href="tech.v3.tensor.html#var--.3Ejvm"><div class="inner"><span>-&gt;jvm</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var--.3Etensor"><div class="inner"><span>-&gt;tensor</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-as-tensor"><div class="inner"><span>as-tensor</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-broadcast"><div class="inner"><span>broadcast</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-clone"><div class="inner"><span>clone</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-columns"><div class="inner"><span>columns</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-compute-tensor"><div class="inner"><span>compute-tensor</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-const-tensor"><div class="inner"><span>const-tensor</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-construct-tensor"><div class="inner"><span>construct-tensor</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-dimensions-dense.3F"><div class="inner"><span>dimensions-dense?</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-dims-suitable-for-desc.3F"><div class="inner"><span>dims-suitable-for-desc?</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-ensure-native"><div class="inner"><span>ensure-native</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-ensure-nd-buffer-descriptor"><div class="inner"><span>ensure-nd-buffer-descriptor</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-ensure-tensor"><div class="inner"><span>ensure-tensor</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-mget"><div class="inner"><span>mget</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-mset.21"><div class="inner"><span>mset!</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-native-tensor"><div class="inner"><span>native-tensor</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-nd-buffer-.3Ebuffer-reader"><div class="inner"><span>nd-buffer-&gt;buffer-reader</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-nd-buffer-descriptor-.3Etensor"><div class="inner"><span>nd-buffer-descriptor-&gt;tensor</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-nd-copy.21"><div class="inner"><span>nd-copy!</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-new-tensor"><div class="inner"><span>new-tensor</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-reduce-axis"><div class="inner"><span>reduce-axis</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-reshape"><div class="inner"><span>reshape</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-rotate"><div class="inner"><span>rotate</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-rows"><div class="inner"><span>rows</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-select"><div class="inner"><span>select</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-simple-dimensions.3F"><div class="inner"><span>simple-dimensions?</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-slice"><div class="inner"><span>slice</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-slice-right"><div class="inner"><span>slice-right</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-tensor-.3Ebuffer"><div class="inner"><span>tensor-&gt;buffer</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-tensor-.3Edimensions"><div class="inner"><span>tensor-&gt;dimensions</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-tensor-copy.21"><div class="inner"><span>tensor-copy!</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-tensor.3F"><div class="inner"><span>tensor?</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-transpose"><div class="inner"><span>transpose</span></div></a></li><li class="depth-1"><a href="tech.v3.tensor.html#var-typed-compute-tensor"><div class="inner"><span>typed-compute-tensor</span></div></a></li></ul></div><div class="namespace-docs" id="content"><h1 class="anchor" id="top">tech.v3.tensor</h1><div class="doc"><div class="markdown"><p>ND bindings for the tech.v3.datatype system. A Tensor is conceptually just a tuple of a buffer and an index operator that is capable of converting indexes in ND space into a single long index into the buffer. Tensors implementent the tech.v3.datatype.NDBuffer interface and outside this file ND objects are expected to simply implement that interface.</p>
<p>This system relies heavily on the tech.v3.tensor.dimensions namespace to provide the optimized indexing operator from ND space to buffer space and back.</p>
<p>There is an ABI in the form of nd-buffer-descriptors that is a map containing:</p>
<ul>
  <li><code>:ptr</code> - long value</li>
  <li><code>:elemwise-datatype</code> - primitive datatype of the buffer.</li>
  <li><code>:shape</code> - buffer of <code>:int64</code> dimensions.</li>
  <li><code>:strides</code> - buffer of <code>:int64</code> byte stride counts.</li>
</ul>
<p>Optionally more keys and the source agrees not to release the source data until this map goes out of scope.</p></div></div><div class="public anchor" id="var--.3Ejvm"><h3>-&gt;jvm</h3><div class="usage"><code>(-&gt;jvm item &amp; {:keys [datatype base-storage], :or {base-storage :persistent-vector}})</code></div><div class="doc"><div class="markdown"><p>Conversion to storage that is efficient for the jvm. Base storage is either jvm-array or persistent-vector.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L715">view source</a></div></div><div class="public anchor" id="var--.3Etensor"><h3>-&gt;tensor</h3><div class="usage"><code>(-&gt;tensor data &amp; {:keys [datatype container-type], :as options})</code></div><div class="doc"><div class="markdown"><p>Convert some data into a tensor via copying the data. The datatype and container type can be specified. The datatype defaults to the datatype of the input data and container type defaults to jvm-heap.</p>
<p>Options:</p>
<ul>
  <li><code>:datatype</code> - Data of the storage. Defaults to the datatype of the passed-in data.</li>
  <li><code>:container-type</code> - Specify the container type of the new tensor. Defaults to  <code>:jvm-heap</code>.</li>
  <li><code>:resource-type</code> - One of <code>tech.v3.resource/track</code> <code>:track-type</code> options. If allocating  native tensors, <code>nil</code> corresponds to <code>:gc:</code>.</li>
</ul></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L536">view source</a></div></div><div class="public anchor" id="var-as-tensor"><h3>as-tensor</h3><div class="usage"><code>(as-tensor data)</code></div><div class="doc"><div class="markdown"><p>Attempts an in-place conversion of this object to a tech.v3.datatype.NDBuffer interface. For a guaranteed conversion, use ensure-tensor.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L567">view source</a></div></div><div class="public anchor" id="var-broadcast"><h3>broadcast</h3><div class="usage"><code>(broadcast t new-shape)</code></div><div class="doc"><div class="markdown"><p>Broadcase an element into a new (larger) shape. The new shape’s dimension must be even multiples of the old shape’s dimensions. Elements are repeated.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/datatype/base.clj#L862">view source</a></div></div><div class="public anchor" id="var-clone"><h3>clone</h3><div class="usage"><code>(clone tens &amp; {:keys [datatype], :or {datatype (dtype-base/elemwise-datatype tens)}, :as options})</code></div><div class="doc"><div class="markdown"><p>Clone a tensor via copying the tensor into a new container. Datatype defaults to the datatype of the tensor and container-type defaults to <code>:java-heap</code>.</p>
<p>Options:</p>
<ul>
  <li><code>:datatype</code> - Specify a new datatype to copy data into.</li>
  <li><code>:container-type</code> - Specify the container type of the new tensor.  Defaults to <code>:jvm-heap</code>.</li>
  <li><code>:resource-type</code> - One of <code>tech.v3.resource/track</code> <code>:track-type</code> options. If allocating  native tensors, <code>nil</code> corresponds to <code>gc:</code>.</li>
</ul></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L695">view source</a></div></div><div class="public anchor" id="var-columns"><h3>columns</h3><div class="usage"><code>(columns src)</code></div><div class="doc"><div class="markdown"><p>Return the columns of the tensor in a randomly-addressable structure.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L687">view source</a></div></div><div class="public anchor" id="var-compute-tensor"><h3>compute-tensor</h3><div class="usage"><code>(compute-tensor shape per-pixel-op datatype)</code><code>(compute-tensor output-shape per-pixel-op)</code></div><div class="doc"><div class="markdown"><p>Create a new tensor which calls into op for every operation.  Op will receive n-dimensional long arguments and the result will be  <code>:unchecked-cast</code>ed to whatever datatype the tensor is reporting.</p>
<p>Example:</p>
<pre><code class="clojure">user&gt; (require '[tech.v3.tensor :as dtt])
nil
user&gt; (dtt/compute-tensor [2 2] (fn [&amp; args] (vec args)) :object)
#tech.v3.tensor&lt;object&gt;[2 2]
[[[0 0] [0 1]]
 [[1 0] [1 1]]]
user&gt; (dtt/compute-tensor [2 2 2] (fn [&amp; args] (vec args)) :object)
#tech.v3.tensor&lt;object&gt;[2 2 2]
[[[[0 0 0] [0 0 1]]
  [[0 1 0] [0 1 1]]]
 [[[1 0 0] [1 0 1]]
  [[1 1 0] [1 1 1]]]]
</code></pre></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L992">view source</a></div></div><div class="public anchor" id="var-const-tensor"><h3>const-tensor</h3><div class="usage"><code>(const-tensor value shape)</code></div><div class="doc"><div class="markdown"><p>Construct a tensor from a value and a shape. Data is represented efficiently via a const-reader.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L596">view source</a></div></div><div class="public anchor" id="var-construct-tensor"><h3>construct-tensor</h3><div class="usage"><code>(construct-tensor buffer dimensions &amp; [metadata])</code></div><div class="doc"><div class="markdown"><p>Construct an implementation of tech.v3.datatype.NDBuffer from a buffer and a dimensions object. See dimensions/dimensions.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L468">view source</a></div></div><div class="public anchor" id="var-dimensions-dense.3F"><h3>dimensions-dense?</h3><div class="usage"><code>(dimensions-dense? tens)</code></div><div class="doc"><div class="markdown"><p>Returns true of the dimensions of a tensor are dense, meaning no gaps due to striding.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L672">view source</a></div></div><div class="public anchor" id="var-dims-suitable-for-desc.3F"><h3>dims-suitable-for-desc?</h3><div class="usage"><code>(dims-suitable-for-desc? item)</code></div><div class="doc"><div class="markdown"><p>Are the dimensions of this object suitable for use in a buffer description? breaks due to striding.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L529">view source</a></div></div><div class="public anchor" id="var-ensure-native"><h3>ensure-native</h3><div class="usage"><code>(ensure-native tens options)</code><code>(ensure-native tens)</code></div><div class="doc"><div class="markdown"><p>Ensure this tensor is native backed and packed. Item is cloned into a native tensor with the same datatype and :resource-type :auto by default.</p>
<p>Options are the same as clone with the exception of :resource-type.</p>
<ul>
  <li><code>:resource-type</code> - Defaults to :auto - used as <code>tech.v3.resource/track track-type</code>.</li>
</ul></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L1132">view source</a></div></div><div class="public anchor" id="var-ensure-nd-buffer-descriptor"><h3>ensure-nd-buffer-descriptor</h3><div class="usage"><code>(ensure-nd-buffer-descriptor tens)</code></div><div class="doc"><div class="markdown"><p>Get a buffer descriptor from the tensor. This may copy the data. If you want to ensure sharing, use the protocol -&gt;nd-buffer-descriptor function.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L757">view source</a></div></div><div class="public anchor" id="var-ensure-tensor"><h3>ensure-tensor</h3><div class="usage"><code>(ensure-tensor item)</code></div><div class="doc"><div class="markdown"><p>Create an implementation of tech.v3.datatype.NDBuffer from an object. If possible, represent the data in-place.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L604">view source</a></div></div><div class="public anchor" id="var-mget"><h3>mget</h3><div class="usage"><code>(mget t x)</code><code>(mget t x y)</code><code>(mget t x y z)</code><code>(mget t x y z &amp; args)</code></div><div class="doc"><div class="markdown"><p>Get an item from an ND object. If fewer dimensions are specified than exist then the return value is a new tensor as a select operation is performed.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/datatype/base.clj#L893">view source</a></div></div><div class="public anchor" id="var-mset.21"><h3>mset!</h3><div class="usage"><code>(mset! t x value)</code><code>(mset! t x y value)</code><code>(mset! t x y z value)</code><code>(mset! t x y z w &amp; args)</code></div><div class="doc"><div class="markdown"><p>Set value(s) on an ND object. If fewer indexes are provided than dimension then a tensor assignment is done and value is expected to be the same shape as the subrect of the tensor as indexed by the provided dimensions. Returns t.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/datatype/base.clj#L913">view source</a></div></div><div class="public anchor" id="var-native-tensor"><h3>native-tensor</h3><div class="usage"><code>(native-tensor shape datatype options)</code><code>(native-tensor shape datatype)</code><code>(native-tensor shape)</code></div><div class="doc"><div class="markdown"><p>Create a new native-backed tensor with a :resource-type :auto default resource type.</p>
<p>Options are the same as new-tensor with some additions:</p>
<ul>
  <li><code>:resource-type</code> - Defaults to :auto - used as <code>tech.v3.resource/track track-type</code>.</li>
  <li><code>:uninitialized?</code> - Defaults to false - do not 0-initialize the memory.</li>
</ul></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L1157">view source</a></div></div><div class="public anchor" id="var-nd-buffer-.3Ebuffer-reader"><h3>nd-buffer-&gt;buffer-reader</h3><div class="usage"><code>(nd-buffer-&gt;buffer-reader b)</code></div><div class="doc"><div class="markdown"></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L849">view source</a></div></div><div class="public anchor" id="var-nd-buffer-descriptor-.3Etensor"><h3>nd-buffer-descriptor-&gt;tensor</h3><div class="usage"><code>(nd-buffer-descriptor-&gt;tensor {:keys [ptr elemwise-datatype shape strides], :as desc})</code></div><div class="doc"><div class="markdown"><p>Given a buffer descriptor, produce a tensor</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L768">view source</a></div></div><div class="public anchor" id="var-nd-copy.21"><h3>nd-copy!</h3><div class="usage"><code>(nd-copy! src dst)</code></div><div class="doc"><div class="markdown"><p>similar to tech.v3.datatype/copy! except this copy is ND aware and parallelizes over the outermost dimension. This useful for compute tensors. If you have tensors such as images, see <code>tensor-copy!</code>.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L1099">view source</a></div></div><div class="public anchor" id="var-new-tensor"><h3>new-tensor</h3><div class="usage"><code>(new-tensor shape &amp; {:keys [datatype container-type], :as options})</code></div><div class="doc"><div class="markdown"><p>Create a new tensor with a given shape.</p>
<p>Options:</p>
<ul>
  <li><code>:datatype</code> - Data of the storage. Defaults to <code>:float64</code>.</li>
  <li><code>:container-type</code> - Specify the container type of the new tensor. Defaults to  <code>:jvm-heap</code>.</li>
  <li><code>:resource-type</code> - One of <code>tech.v3.resource/track</code> <code>:track-type</code> options. If allocating  native tensors, <code>nil</code> corresponds to <code>:gc:</code>.</li>
</ul></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L576">view source</a></div></div><div class="public anchor" id="var-reduce-axis"><h3>reduce-axis</h3><div class="usage"><code>(reduce-axis reduce-fn tensor axis res-dtype)</code><code>(reduce-axis reduce-fn tensor axis)</code><code>(reduce-axis reduce-fn tensor)</code></div><div class="doc"><div class="markdown"><p>Reduce a tensor along an axis using reduce-fn on the elemwise entries.</p>
<ul>
  <li>reduce-fn - lazily applied reduction applied to each input. Inputs are 1-dimensional vectors. Use clone to force the operation.</li>
  <li>tensor - input tensor to use.</li>
  <li>axis - Defaults to -1 meaning the last axis. So the default would reduce across the rows of a matrix.</li>
  <li>res-dtype - result datatype, defaults to the datatype of the incoming tensor.</li>
</ul>
<p>Example:</p>
<pre><code class="clojure">user&gt; t
#tech.v3.tensor&lt;object&gt;[4 3]
[[0  1  2]
 [3  4  5]
 [6  7  8]
 [9 10 11]]
user&gt; (dtt/reduce-axis dfn/sum t 0)
#tech.v3.tensor&lt;object&gt;[3]
[18.00 22.00 26.00]
user&gt; (dtt/reduce-axis dfn/sum t 1)
#tech.v3.tensor&lt;object&gt;[4]
[3.000 12.00 21.00 30.00]
user&gt; (dtt/reduce-axis dfn/sum t)
#tech.v3.tensor&lt;object&gt;[4]
[3.000 12.00 21.00 30.00]
user&gt; (dtt/reduce-axis dfn/sum t 0 :float64)
#tech.v3.tensor&lt;float64&gt;[3]
[18.00 22.00 26.00]


user&gt; (def t (dtt/new-tensor [2 3 5]))
#'user/t
user&gt; (dtype/shape (dtt/reduce-axis dfn/sum t 0))
[3 5]
user&gt; (dtype/shape (dtt/reduce-axis dfn/sum t 1))
[2 5]
user&gt; (dtype/shape (dtt/reduce-axis dfn/sum t 2))
[2 3]
</code></pre></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L1178">view source</a></div></div><div class="public anchor" id="var-reshape"><h3>reshape</h3><div class="usage"><code>(reshape t new-shape)</code></div><div class="doc"><div class="markdown"><p>Reshape this item into a new shape. For this to work, the tensor namespace must be required. Always returns a tensor.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/datatype/base.clj#L779">view source</a></div></div><div class="public anchor" id="var-rotate"><h3>rotate</h3><div class="usage"><code>(rotate t offset-vec)</code></div><div class="doc"><div class="markdown"><p>Rotate dimensions. Offset-vec must have same count as the rank of t. Elements of that dimension are rotated by the amount specified in the offset vector with 0 indicating no rotation.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/datatype/base.clj#L869">view source</a></div></div><div class="public anchor" id="var-rows"><h3>rows</h3><div class="usage"><code>(rows src)</code></div><div class="doc"><div class="markdown"><p>Return the rows of the tensor in a randomly-addressable structure.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L679">view source</a></div></div><div class="public anchor" id="var-select"><h3>select</h3><div class="usage"><code>(select t &amp; new-shape)</code></div><div class="doc"><div class="markdown"><p>Perform a subrect projection or selection Shape arguments may be readers, ranges, integers, or the keywords [:all :lla]. :all means take the entire dimension, :lla means reverse the dimension. Arguments are applied left to right and any missing arguments are assumed to be :all.</p>
<p>Example:</p>
<pre><code class="clojure">user&gt; (dtt/select (dtt/-&gt;tensor [1 2 3]) [0 2])
#tech.v3.tensor&lt;object&gt;[2]
[1 3]

user&gt; (def tensor (dtt/-&gt;tensor
            [[1 2 3]
             [4 5 6]]))
#'user/tensor
user&gt; (dtt/select tensor [1] [0 2])
#tech.v3.tensor&lt;object&gt;[2]
[4 6]
user&gt; (dtt/select tensor [0 1] [1 2])
#tech.v3.tensor&lt;object&gt;[2 2]
[[2 3]
 [5 6]]
</code></pre></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/datatype/base.clj#L788">view source</a></div></div><div class="public anchor" id="var-simple-dimensions.3F"><h3>simple-dimensions?</h3><div class="usage"><code>(simple-dimensions? item)</code></div><div class="doc"><div class="markdown"><p>Are the dimensions of this object simple meaning read in order with no breaks due to striding.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L522">view source</a></div></div><div class="public anchor" id="var-slice"><h3>slice</h3><div class="usage"><code>(slice t n-dims)</code></div><div class="doc"><div class="markdown"><p>Slice off Y leftmost dimensions returning a reader of objects. If all dimensions are sliced of then the reader reads actual elements, else it reads subrect tensors.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/datatype/base.clj#L877">view source</a></div></div><div class="public anchor" id="var-slice-right"><h3>slice-right</h3><div class="usage"><code>(slice-right t n-dims)</code></div><div class="doc"><div class="markdown"><p>Slice off Y rightmost dimensions returning a reader of objects. If all dimensions are sliced of then the reader reads actual elements, else it reads subrect tensors.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/datatype/base.clj#L885">view source</a></div></div><div class="public anchor" id="var-tensor-.3Ebuffer"><h3>tensor-&gt;buffer</h3><div class="usage"><code>(tensor-&gt;buffer item)</code></div><div class="doc"><div class="markdown"><p>Get the buffer from a tensor.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L506">view source</a></div></div><div class="public anchor" id="var-tensor-.3Edimensions"><h3>tensor-&gt;dimensions</h3><div class="usage"><code>(tensor-&gt;dimensions item)</code></div><div class="doc"><div class="markdown"><p>Get the dimensions object from a tensor.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L514">view source</a></div></div><div class="public anchor" id="var-tensor-copy.21"><h3>tensor-copy!</h3><div class="usage"><code>(tensor-copy! src dst options)</code><code>(tensor-copy! src dst)</code></div><div class="doc"><div class="markdown"><p>Specialized copy with optimized pathways for when tensors have regions of contiguous data. As an example consider a sub-image of a larger image. Each row can be copied contiguously into a new image but there are gaps between them.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L658">view source</a></div></div><div class="public anchor" id="var-tensor.3F"><h3>tensor?</h3><div class="usage"><code>(tensor? item)</code></div><div class="doc"><div class="markdown"><p>Returns true if this implements the tech.v3.datatype.NDBuffer interface.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L500">view source</a></div></div><div class="public anchor" id="var-transpose"><h3>transpose</h3><div class="usage"><code>(transpose t reorder-indexes)</code></div><div class="doc"><div class="markdown"><p>In-place transpose an n-d object into a new shape. Returns a tensor.</p>
<p>reorder-indexes are the relative indexes of the old indexes</p>
<p>Example:</p>
<pre><code class="clojure">user&gt; (def tensor (dtt/-&gt;tensor (partition 2 (partition 3 (flatten (repeat 6 [:r :g :b]))))))
#'user/tensor
user&gt; tensor
#tech.v3.tensor&lt;object&gt;[3 2 3]
[[[:r :g :b]
  [:r :g :b]]
 [[:r :g :b]
  [:r :g :b]]
 [[:r :g :b]
  [:r :g :b]]]
user&gt; (dtt/transpose tensor [2 0 1])
#tech.v3.tensor&lt;object&gt;[3 3 2]
[[[:r :r]
  [:r :r]
  [:r :r]]
 [[:g :g]
  [:g :g]
  [:g :g]]
 [[:b :b]
  [:b :b]
  [:b :b]]]
user&gt; (dtt/transpose tensor [1 2 0])
#tech.v3.tensor&lt;object&gt;[2 3 3]
[[[:r :r :r]
  [:g :g :g]
  [:b :b :b]]
 [[:r :r :r]
  [:g :g :g]
  [:b :b :b]]]
</code></pre></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/datatype/base.clj#L819">view source</a></div></div><div class="public anchor" id="var-typed-compute-tensor"><h3>typed-compute-tensor</h3><h4 class="type">macro</h4><div class="usage"><code>(typed-compute-tensor datatype advertised-datatype rank shape op-code-args op-code)</code><code>(typed-compute-tensor advertised-datatype rank shape op-code-args op-code)</code><code>(typed-compute-tensor advertised-datatype shape op-code-args op-code)</code></div><div class="doc"><div class="markdown"><p>Fastest possible inline compute tensor. The code to generate the next element is output inline into the tensor definition.</p>
<p>For the 4 argument version to work, shape must be compile time introspectable object with count so for instance <code>[a b c]</code> will work but item-shape will throw an exception.</p>
<ul>
  <li><code>:datatype</code> - One of #{:int64 :float64} or :object is assumed. This indicates  the tensor interface definition and read operations that will be implemented.  See ’java/tech/v3/datatype/[Long|Double|Object]TensorReader.java.</li>
  <li><code>:advertised-datatype</code> - Datatype you will tell the world.</li>
  <li><code>:rank</code> - compile time introspectable rank. Indicates which ndReadX overloads  will be implemented.</li>
  <li><code>:shape</code> - Shape of the output tensor.</li>
  <li><code>:op-code-args</code> - Op code arguments. Expected to be a vector of argument  names such as <code>[y x c].  Let destructuring is *NOT* supported beyond 3
   variables at this time.!!!</code>.</li>
  <li><code>:op-code</code> - Code which executes the read operation.</li>
</ul>
<p>Results in an implementation of NDBuffer which efficiently performs a 1,2 or 3 dimension ND read operation.</p></div></div><div class="src-link"><a href="https://github.com/cnuernber/dtype-next/blob/master/src/tech/v3/tensor.clj#L877">view source</a></div></div></div></body></html>